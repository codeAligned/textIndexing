\section{Compressed Suffix Array}

Theorem~\ref{thm:psiValuesIncreasing} tells us that the values of $\Psi$ form at most $\sigma$ increasing sequences in the range $[0,n-1]$. We can use this fact to compress this data and obtain what is called a $\Psi$-based \defi{compressed suffix array}{Compressed Suffix Array} $\id{CSA}_\Psi$.

\subsection{Elias-Fano-Encoded $\id{CSA}_\Psi$}

We can use Elias-Fano-Encoding to encode each of the increasing subsequences of $\Psi$, each in $[0, n-1]$. Let's calculate the needed space for each of these sequences. For each $c \in \Sigma$, $n_c$ is the number of occurrences of $c$ in the text (so the length of the increasing run corresponding to the suffixes starting with $c$).

\begin{align}
  \begin{aligned}
    \vert \id{CSA}_\Psi \vert
    &\stackrel{\mathclap{\text{\ref{thm:eliasFanoEncoding}}}}{=}
    \sum_{c \in \Sigma} \left(2n_c + n_c\log\frac{n}{n_c} + o(n_c)\right) \\
    &= \sum_{c \in \Sigma} 2n_c + n\sum_{c \in \Sigma}\frac{n_c}{n}\log\frac{n}{n_c} + o(n) \\
    &\stackrel{\mathclap{\text{\ref{def:zerothOrderEntropy}}}}{=} 2n + n\mathcal{H}_0(T) + o(n)
  \end{aligned}
\end{align}

In addition to these $2n + n\mathcal{H}_0(T) + o(n)$ bits we need another $\mathcal{O}(\sigma\log n)$ bits to store the character boundaries.

\begin{algorithm}[htb]
  \begin{codebox}
    \Procname{$\proc{Compare-CSA}(P, i)$}
    \li $k \gets 0$
    \li \While $k < \vert P \vert$
        \Do
    \li   \If $C[P[k] + 1] - 1 < i$
          \label{line:compareCSACheckSmaller}
          \Then
    \li     \Return $-1$ \>\>\>\>\Comment $P$ smaller than suffix $\id{SA}[i]$.
    \li   \ElseIf $C[P[k]] > i$
          \label{line:compareCSACheckBigger}
          \Then
    \li     \Return $1$ \>\>\>\>\Comment $P$ larger than suffix $\id{SA}[i]$.
          \End
    \li   $k \gets k + 1$
    \li   $i \gets \Psi[i]$
        \End
    \li \Return $0$ \>\>\>\>\>\>\Comment $P$ equal to the first $\vert P \vert$ character of the suffix $\id{SA}[i]$.
  \end{codebox}
  \caption{Compare a pattern $P$ to suffix $\id{SA}[i]$.}
  \label{alg:compareCompressedSuffixArrayPsi}
\end{algorithm}

We can use Algorithm~\ref{alg:compareCompressedSuffixArrayPsi} to search for some pattern $P$ in the compressed suffix array. All we need to store is array $C$ giving the first position for each character and array $\Psi$. We can then binary search for the correct position each time using \proc{Compare-CSA} to check whether the corresponding entry matches $P$. \proc{Compare-CSA} compares the pattern from left to right. Index $C[P[k] + 1] - 1$ in Line~\ref{line:compareCSACheckSmaller} is the last position in the suffix array starting with $P[k]$ while index $C[P[k]]$ is the first position in the suffix array starting with $P[k]$. The whole process needs time $\mathcal{O}(m\log n)$.

\subsection{Elias-$\delta$-Encoded $\id{CSA}_\Psi$}

Another way to encode and compress the values of $\Psi$ is by using an Elias-$\delta$-code.

\begin{Definition}
  \label{def:eliasDeltaEncoding}
  \defi{Elias-$\delta$-Encoding}{Elias-$\delta$-Encoding} is a way to represent a positive integer $x$ using $\lfloor\log (x)\rfloor+2\lfloor\log(\lfloor\log (x)\rfloor + 1)\rfloor+1$ bits.

  To encode $x$ execute the following steps:
  \begin{enumerate}
    \item Let $N = \lfloor \log x \rfloor$ be the highest power of two in $x$, so $2^N \leq x < 2^{N+1}$.
    \item Let $L = \lfloor \log N + 1 \rfloor$ be the highest power of two in $N+1$, so $2^L \leq N+1 < 2^{L + 1}$.
    \item Write $L$ zeros.
    \item Write the $L+1$ bit representation of $N+1$.
    \item Write the last $N$ bits of $X$ (all but the leading one).
  \end{enumerate}
\end{Definition}

Let's now calculate the space needed to store the values of $\Psi$ if an Elias-$\delta$-Encoding is used. For each character $c \in \Sigma$ we gap-encode its increasing $\Psi$ sequence. We define 
\begin{align}
  g_{c,i} &=
  \begin{cases}
    \Psi[C[c]] & \text{for $i = 0$} \\  
    \Psi[C[c] + i] - \Psi[C[c] + i - 1] & \text{for $i > 0$}
  \end{cases}
\end{align}
to be the $i$-th gap length of the increasing sequence corresponding to symbol $c$. The space for the compressed suffix array is then:
\begin{align}
  \begin{aligned}
    \vert \id{CSA}_\Psi \vert
    &\stackrel{\mathclap{\text{\ref{def:eliasDeltaEncoding}}}}{=}
    \sum\limits_{c \in \Sigma} \sum\limits_{i = 0}^{n_c - 1}
    \left(\log g_{c,i} + 2 \log\log g_{c,i} + \mathcal{O}(1)\right) \\
    &\leq\mathcal{O}(n) + \sum\limits_{c \in \Sigma}\sum\limits_{i = 0}^{n_c - 1}
    \left(\log\frac{n}{n_c}+2\log\log\frac{n}{n_c}\right) \\
    &=\mathcal{O}(n) + n\sum\limits_{c \in \Sigma}\frac{n_c}{n}
    \left(\log\frac{n}{n_c}+2\log\log\frac{n}{n_c}\right) \\
    &=\mathcal{O}(n) + n\sum\limits_{c \in \Sigma}\frac{n_c}{n}\log\frac{n}{n_c} + n\sum\limits_{c \in \Sigma}\frac{2n_c}{n}\log\log\frac{n}{n_c} \\
    &=n\mathcal{H}_0(T) + \mathcal{O}(n \log\log n)
  \end{aligned}
\end{align}

In the first step we just applied the definition of Elias-$\delta$-Encoding, before estimating an upper bound for the logarithms in the second step. In the third step we now used that the summation index $i$ does not appear in the expression anymore. Then we split the summation into two sums and plug the definition for the zeroth-order entropy.
